[
  {
    "date": "Feb 18, 9.45 am",
    "name": "Packages in python",
    "url": "https://docs.python.org/3/tutorial/modules.html#importing-from-a-package",
    "urlCorrect": true,
    "text": "6.4. Packages\nPackages are a way of structuring Python's module namespace by using \"dotted module names\". For example, the module name `A.B` designates a submodule named B in a package named A. Just like the use of modules saves the authors of different modules from having to worry about each other's global variable names, the use of dotted module names saves the authors of multi-module packages like `NumPy` or `Pillow` from having to worry about each other's module names.\n\nSuppose you want to design a collection of modules (a \"package\") for the uniform handling of sound files and sound data. There are many different sound file formats (usually recognized by their extension, for example: `.wav`, `.aiff`, `.au`), so you may need to create and maintain a growing collection of modules for the conversion between the various file formats. There are also many different operations you might want to perform on sound data (such as mixing, adding echo, applying an equalizer function, creating an artificial stereo effect), so in addition you will be writing a never-ending stream of modules to perform these operations. Here's a possible structure for your package (expressed in terms of a hierarchical filesystem):"
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Django URL dispatcher",
    "url": "https://docs.djangoproject.com/en/6.0/topics/http/urls/",
    "urlCorrect": null,
    "text": "URL dispatcher\nA clean, elegant URL scheme is an important detail in a high-quality web application. Django lets you design URLs however you want, with no framework limitations.\n\nSee Cool URIs don't change, by World Wide Web creator Tim Berners-Lee, for excellent arguments on why URLs should be clean and usable.\n\nOverview\nTo design URLs for an app, you create a Python module informally called a `URLconf` (URL configuration). This module is pure Python code and is a mapping between URL path expressions to Python functions (your views).\n\nThis mapping can be as short or as long as needed. It can reference other mappings. And, because it's pure Python code, it can be constructed dynamically.\n\nDjango also provides a way to translate URLs according to the active language. See the internationalization documentation for more information."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "WSGI vs ASGI",
    "url": "https://asgi.readthedocs.io/",
    "urlCorrect": null,
    "text": "WSGI (Web Server Gateway Interface) is the original Python web server standard and is designed for synchronous request‚Äìresponse handling, meaning each worker processes one request at a time and blocks while waiting on I/O like database calls. It works well for traditional web apps built around short, stateless HTTP requests and is the model historically used by frameworks like Django and Flask with servers such as `Gunicorn` or `uWSGI`. ASGI (Asynchronous Server Gateway Interface) is the newer successor that supports asynchronous execution, allowing a single worker to manage many concurrent connections by pausing tasks while waiting on I/O and handling others meanwhile. ASGI also adds support for protocols beyond simple HTTP, including WebSockets, background tasks, and streaming responses. Modern async-first frameworks like FastAPI and Starlette rely on ASGI servers such as `Uvicorn` or `Daphne`. In practice, WSGI is simpler and perfectly adequate for many CRUD-style apps, while ASGI is preferred when you need high concurrency, real-time communication, or long-lived connections. Conceptually, WSGI is \"one request handled start-to-finish,\" whereas ASGI is \"many requests cooperatively interleaved.\""
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "How and when Django is async vs sync",
    "url": "https://docs.djangoproject.com/en/stable/topics/async/",
    "urlCorrect": null,
    "text": "Django historically ran entirely synchronously, and much of its core ecosystem (especially the ORM, middleware, and many third-party packages) still operates in blocking mode. Modern Django versions can run on an ASGI server and allow you to write `async def` views, async middleware, and non-blocking external API calls, which enables true asynchronous handling in those parts of the stack. However, whenever Django encounters synchronous components‚Äîsuch as most database ORM operations or legacy middleware‚Äîit transparently executes them in a thread pool, effectively reverting that portion of the request to synchronous behavior. This means a Django project can be partly async at the entry point but still behave mostly sync internally if it relies heavily on the traditional ORM and packages. Django's async features therefore help most when your view spends significant time awaiting external network calls, handling streaming responses, or supporting WebSockets (often via `Channels`). For typical database-driven CRUD pages, the practical performance difference between sync and async Django is often small. In short, Django is \"async-capable,\" but whether it truly runs asynchronously depends on how much of your request path avoids blocking components."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Django vs NestJS async model",
    "url": "https://docs.nestjs.com/",
    "urlCorrect": null,
    "text": "Yes ‚Äî NestJS is \"more async by default\" than Django, but the reason comes from the ecosystems they sit on.\n\nDjango vs NestJS async model:\nDjango started as a synchronous framework and later added async support, so although it can run on ASGI and accept `async` views, much of its core (especially the ORM and many third-party packages) still performs blocking operations that Django pushes into a thread pool. In contrast, NestJS runs on Node.js, whose runtime is built around an event loop and non-blocking I/O from the ground up, so database calls, HTTP requests, and file operations are typically handled through promises and async functions automatically. That means a typical NestJS endpoint is naturally concurrent even if you don't explicitly think about async behavior, while a Django endpoint only gains real async advantages if you intentionally use async views plus async-compatible libraries. Practically, Django often behaves like a synchronous framework with optional async escape hatches, whereas NestJS behaves like an asynchronous framework with occasional synchronous CPU work. This difference shows up most under high concurrent network load (many simultaneous requests waiting on I/O), where NestJS tends to scale concurrency per process more naturally. However, for CPU-heavy work (like OCR, embeddings, or ML inference), neither framework gains much from async alone ‚Äî both still need worker processes or job queues.\n\nSimple rule of thumb:\n\n```\nDjango = sync-first, async-capable\nNestJS = async-first, sync-allowed\n```"
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "I/O-blocking vs CPU-blocking",
    "url": "https://docs.python.org/3/library/asyncio.html",
    "urlCorrect": null,
    "text": "**I/O-blocking** happens when a program is waiting for something external ‚Äî like a database query, network request, disk read, or API call ‚Äî and the thread can't continue until the data arrives. During that wait, the CPU isn't really doing useful computation, so async or non-blocking systems can switch to handling other tasks in the meantime. This is why async frameworks shine for web servers that spend lots of time waiting on databases or remote services.\n\n**CPU-blocking** (CPU-bound work) happens when the program is actively using the processor to perform calculations, such as image processing, OCR, encryption, large loops, or ML inference. In this case the CPU is busy the whole time, so async doesn't help much ‚Äî the task must finish computing before the CPU is free. CPU-bound workloads scale better with multiprocessing, worker queues, or more cores rather than async I/O. In short: I/O-blocking = waiting on external data, CPU-blocking = busy doing heavy computation."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "ML in monolith vs microservice: CPU-blocking to I/O-waiting",
    "url": "https://cloud.google.com/run/docs",
    "urlCorrect": null,
    "text": "If you have a monolithic backend that's running both the web app and an ML model, you'll often run into CPU-blocking latency. But if you move the ML model to its own microservice or `Cloud Run` function, you add I/O latency (calling out and back from the microservice), which an async architecture can handle without blocking. The ML model still takes whatever time it takes, but it frees up the rest of the application.\n\nYes ‚Äî that's exactly the right mental model.\n\nIn a monolithic backend, if a request triggers an ML model that takes 2‚Äì5 seconds of heavy computation, that work is CPU-bound and ties up the worker (or at least one CPU core). During that time the web server can't easily use that same worker to serve other requests, so latency and throughput suffer unless you run many workers or background queues. Moving the ML model into a separate microservice or `Cloud Run` job doesn't make the model faster, but it converts the web app's perspective from \"CPU work\" into mostly I/O waiting (send request ‚Üí wait for response). Once it becomes I/O, an async web server can handle many such pending requests concurrently, freeing the main app to continue serving users while the ML service computes. You do add network latency and serialization overhead, but in practice this is usually small compared to multi-second model inference time. The bigger benefit is architectural isolation: the ML service can scale independently (more CPUs, GPUs, autoscaling) without forcing the web frontend to scale the same way.\n\nThe practical production pattern is: web app = fast, mostly I/O + orchestration; ML service = CPU/GPU heavy worker, often behind a queue or async HTTP call."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Serialization",
    "url": "https://docs.python.org/3/library/json.html",
    "urlCorrect": null,
    "text": "What is serialization?\n\nSerialization is the process of converting an in-memory object (like a Python `dict`, class instance, or model output) into a format that can be stored, sent over a network, or written to disk ‚Äî usually something like JSON, bytes, or a binary protocol. The reverse process is called deserialization, which reconstructs the object back into usable program data.\n\nFor example, inside your Python backend you might have:\n\n```\n{\"user_id\": 5, \"score\": 0.92}\n```\n\nBefore sending it to another service, it gets serialized into JSON (the same representation here). When the other service receives it, it deserializes that JSON back into its own data structure.\n\nSerialization matters because computers can't directly transmit complex in-memory objects (like Python classes, tensors, or ORM models) ‚Äî they must be flattened into a standard transferable representation first. In ML systems, serialization overhead can include converting images, tensors, or embeddings into bytes or JSON, which adds a small amount of processing time and payload size. In short: serialization = turning program objects into transferable data; deserialization = rebuilding them on the other side.\n\nBackend engineers often choose between formats in production (e.g. JSON vs Protobuf vs MessagePack); that decision becomes very relevant once you start splitting ML into microservices."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "JSON vs Protobuf vs MessagePack",
    "url": "https://developers.google.com/protocol-buffers",
    "urlCorrect": null,
    "text": "Here are the three serialization formats backend engineers most commonly choose in production ‚Äî JSON, Protobuf, and MessagePack ‚Äî and when each makes sense.\n\nüü¢ JSON (JavaScript Object Notation) ‚Äî the default everywhere\n\nJSON is a human-readable text format and the universal standard for web APIs. It's extremely easy to debug, supported natively in browsers and every programming language, and perfect for REST APIs, configuration, and general service communication. The downside is that it's relatively verbose (large payload size) and slower to parse compared to binary formats, especially for large ML inputs/outputs or high-throughput systems. Despite this, most companies still use JSON for external APIs because developer productivity and interoperability matter more than raw efficiency. Rule of thumb: use JSON unless you have a concrete performance reason not to.\n\nüîµ Protobuf (Protocol Buffers) ‚Äî the high-performance structured choice\n\nProtobuf is a compact binary serialization format created by Google that requires you to define a strict schema (`.proto` file) describing your data structures. It produces much smaller payloads than JSON and serializes/deserializes very fast, making it popular for microservice-to-microservice communication, internal APIs, and high-scale systems (especially with `gRPC`). The tradeoff is reduced human readability and more setup: you must maintain schemas and generate code for each language. Protobuf shines when you have many services talking frequently, large payloads, or need strong contracts between teams.\n\nüü£ MessagePack ‚Äî the \"binary JSON\" middle ground\n\nMessagePack is a binary format designed to represent the same data structures as JSON but in a compact binary form. It keeps JSON's flexible schema-less style (no proto files needed) while shrinking payload size and improving speed, so it's often described as \"JSON but faster and smaller.\" It's simpler to adopt than Protobuf and still efficient, which makes it useful for internal APIs, caching layers, or streaming structured data where JSON is too heavy but strict schemas feel overkill. The downside is it's less standardized across big enterprise systems than JSON or Protobuf. Think of MessagePack as the pragmatic performance upgrade when JSON starts hurting but you don't want schema bureaucracy.\n\nüß† The real-world decision shortcut engineers use\n\nüåç Public API ‚Üí JSON (almost always)\n\nüè¢ Internal microservices at scale ‚Üí Protobuf (often with gRPC)\n\n‚öôÔ∏è Need smaller/faster than JSON but want flexibility ‚Üí MessagePack"
  },
  {
    "date": "Feb 18, 10.09 am",
    "name": "Django project vs app",
    "url": "https://docs.djangoproject.com/en/stable/intro/tutorial01/",
    "urlCorrect": null,
    "text": "Now that your environment ‚Äì a \"project\" ‚Äì is set up, you're set to start doing work.\n\nEach application you write in Django consists of a Python package that follows a certain convention. Django comes with a utility that automatically generates the basic directory structure of an app, so you can focus on writing code rather than creating directories.\n\nProjects vs. apps\n\nWhat's the difference between a project and an app? An app is a web application that does something ‚Äì e.g., a blog system, a database of public records or a small poll app. A project is a collection of configuration and apps for a particular website. A project can contain multiple apps. An app can be in multiple projects."
  },
  {
    "date": "Feb 18, 10.11 am",
    "name": "django-admin and manage.py",
    "url": "https://docs.djangoproject.com/en/stable/ref/django-admin/",
    "urlCorrect": null,
    "text": "django-admin and manage.py¬∂\n`django-admin` is Django's command-line utility for administrative tasks. This document outlines all it can do.\n\nIn addition, `manage.py` is automatically created in each Django project. It does the same thing as `django-admin` but also sets the `DJANGO_SETTINGS_MODULE` environment variable so that it points to your project's `settings.py` file.\n\nThe `django-admin` script should be on your system path if you installed Django via `pip`. If it's not in your path, ensure you have your virtual environment activated.\n\nGenerally, when working on a single Django project, it's easier to use `manage.py` than `django-admin`. If you need to switch between multiple Django settings files, use `django-admin` with `DJANGO_SETTINGS_MODULE` or the `--settings` command line option.\n\nThe command-line examples throughout this document use `django-admin` to be consistent, but any example can use `manage.py` or `python -m django` just as well.\n\nUsage¬∂\n\n```\n$ django-admin <command> [options]\n$ manage.py <command> [options]\n$ python -m django <command> [options]\n```"
  }
]

[
  {
    "date": "Feb 18, 9.45 am",
    "name": "Packages in python",
    "url": "https://docs.python.org/3/tutorial/modules.html#importing-from-a-package",
    "urlCorrect": true,
    "text": "6.4. Packages\nPackages are a way of structuring Python's module namespace by using \"dotted module names\". For example, the module name `A.B` designates a submodule named B in a package named A. Just like the use of modules saves the authors of different modules from having to worry about each other's global variable names, the use of dotted module names saves the authors of multi-module packages like `NumPy` or `Pillow` from having to worry about each other's module names.\n\nSuppose you want to design a collection of modules (a \"package\") for the uniform handling of sound files and sound data. There are many different sound file formats (usually recognized by their extension, for example: `.wav`, `.aiff`, `.au`), so you may need to create and maintain a growing collection of modules for the conversion between the various file formats. There are also many different operations you might want to perform on sound data (such as mixing, adding echo, applying an equalizer function, creating an artificial stereo effect), so in addition you will be writing a never-ending stream of modules to perform these operations. Here's a possible structure for your package (expressed in terms of a hierarchical filesystem):"
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Django URL dispatcher",
    "url": "https://docs.djangoproject.com/en/6.0/topics/http/urls/",
    "urlCorrect": null,
    "text": "URL dispatcher\nA clean, elegant URL scheme is an important detail in a high-quality web application. Django lets you design URLs however you want, with no framework limitations.\n\nSee Cool URIs don't change, by World Wide Web creator Tim Berners-Lee, for excellent arguments on why URLs should be clean and usable.\n\nOverview\nTo design URLs for an app, you create a Python module informally called a `URLconf` (URL configuration). This module is pure Python code and is a mapping between URL path expressions to Python functions (your views).\n\nThis mapping can be as short or as long as needed. It can reference other mappings. And, because it's pure Python code, it can be constructed dynamically.\n\nDjango also provides a way to translate URLs according to the active language. See the internationalization documentation for more information."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "WSGI vs ASGI",
    "url": "https://asgi.readthedocs.io/",
    "urlCorrect": null,
    "text": "WSGI (Web Server Gateway Interface) is the original Python web server standard and is designed for synchronous request‚Äìresponse handling, meaning each worker processes one request at a time and blocks while waiting on I/O like database calls. It works well for traditional web apps built around short, stateless HTTP requests and is the model historically used by frameworks like Django and Flask with servers such as `Gunicorn` or `uWSGI`. ASGI (Asynchronous Server Gateway Interface) is the newer successor that supports asynchronous execution, allowing a single worker to manage many concurrent connections by pausing tasks while waiting on I/O and handling others meanwhile. ASGI also adds support for protocols beyond simple HTTP, including WebSockets, background tasks, and streaming responses. Modern async-first frameworks like FastAPI and Starlette rely on ASGI servers such as `Uvicorn` or `Daphne`. In practice, WSGI is simpler and perfectly adequate for many CRUD-style apps, while ASGI is preferred when you need high concurrency, real-time communication, or long-lived connections. Conceptually, WSGI is \"one request handled start-to-finish,\" whereas ASGI is \"many requests cooperatively interleaved.\""
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "How and when Django is async vs sync",
    "url": "https://docs.djangoproject.com/en/stable/topics/async/",
    "urlCorrect": null,
    "text": "Django historically ran entirely synchronously, and much of its core ecosystem (especially the ORM, middleware, and many third-party packages) still operates in blocking mode. Modern Django versions can run on an ASGI server and allow you to write `async def` views, async middleware, and non-blocking external API calls, which enables true asynchronous handling in those parts of the stack. However, whenever Django encounters synchronous components‚Äîsuch as most database ORM operations or legacy middleware‚Äîit transparently executes them in a thread pool, effectively reverting that portion of the request to synchronous behavior. This means a Django project can be partly async at the entry point but still behave mostly sync internally if it relies heavily on the traditional ORM and packages. Django's async features therefore help most when your view spends significant time awaiting external network calls, handling streaming responses, or supporting WebSockets (often via `Channels`). For typical database-driven CRUD pages, the practical performance difference between sync and async Django is often small. In short, Django is \"async-capable,\" but whether it truly runs asynchronously depends on how much of your request path avoids blocking components."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Django vs NestJS async model",
    "url": "https://docs.nestjs.com/",
    "urlCorrect": null,
    "text": "Yes ‚Äî NestJS is \"more async by default\" than Django, but the reason comes from the ecosystems they sit on.\n\nDjango vs NestJS async model:\nDjango started as a synchronous framework and later added async support, so although it can run on ASGI and accept `async` views, much of its core (especially the ORM and many third-party packages) still performs blocking operations that Django pushes into a thread pool. In contrast, NestJS runs on Node.js, whose runtime is built around an event loop and non-blocking I/O from the ground up, so database calls, HTTP requests, and file operations are typically handled through promises and async functions automatically. That means a typical NestJS endpoint is naturally concurrent even if you don't explicitly think about async behavior, while a Django endpoint only gains real async advantages if you intentionally use async views plus async-compatible libraries. Practically, Django often behaves like a synchronous framework with optional async escape hatches, whereas NestJS behaves like an asynchronous framework with occasional synchronous CPU work. This difference shows up most under high concurrent network load (many simultaneous requests waiting on I/O), where NestJS tends to scale concurrency per process more naturally. However, for CPU-heavy work (like OCR, embeddings, or ML inference), neither framework gains much from async alone ‚Äî both still need worker processes or job queues.\n\nSimple rule of thumb:\n\n```\nDjango = sync-first, async-capable\nNestJS = async-first, sync-allowed\n```"
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "I/O-blocking vs CPU-blocking",
    "url": "https://docs.python.org/3/library/asyncio.html",
    "urlCorrect": null,
    "text": "**I/O-blocking** happens when a program is waiting for something external ‚Äî like a database query, network request, disk read, or API call ‚Äî and the thread can't continue until the data arrives. During that wait, the CPU isn't really doing useful computation, so async or non-blocking systems can switch to handling other tasks in the meantime. This is why async frameworks shine for web servers that spend lots of time waiting on databases or remote services.\n\n**CPU-blocking** (CPU-bound work) happens when the program is actively using the processor to perform calculations, such as image processing, OCR, encryption, large loops, or ML inference. In this case the CPU is busy the whole time, so async doesn't help much ‚Äî the task must finish computing before the CPU is free. CPU-bound workloads scale better with multiprocessing, worker queues, or more cores rather than async I/O. In short: I/O-blocking = waiting on external data, CPU-blocking = busy doing heavy computation."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "ML in monolith vs microservice: CPU-blocking to I/O-waiting",
    "url": "https://cloud.google.com/run/docs",
    "urlCorrect": null,
    "text": "If you have a monolithic backend that's running both the web app and an ML model, you'll often run into CPU-blocking latency. But if you move the ML model to its own microservice or `Cloud Run` function, you add I/O latency (calling out and back from the microservice), which an async architecture can handle without blocking. The ML model still takes whatever time it takes, but it frees up the rest of the application.\n\nYes ‚Äî that's exactly the right mental model.\n\nIn a monolithic backend, if a request triggers an ML model that takes 2‚Äì5 seconds of heavy computation, that work is CPU-bound and ties up the worker (or at least one CPU core). During that time the web server can't easily use that same worker to serve other requests, so latency and throughput suffer unless you run many workers or background queues. Moving the ML model into a separate microservice or `Cloud Run` job doesn't make the model faster, but it converts the web app's perspective from \"CPU work\" into mostly I/O waiting (send request ‚Üí wait for response). Once it becomes I/O, an async web server can handle many such pending requests concurrently, freeing the main app to continue serving users while the ML service computes. You do add network latency and serialization overhead, but in practice this is usually small compared to multi-second model inference time. The bigger benefit is architectural isolation: the ML service can scale independently (more CPUs, GPUs, autoscaling) without forcing the web frontend to scale the same way.\n\nThe practical production pattern is: web app = fast, mostly I/O + orchestration; ML service = CPU/GPU heavy worker, often behind a queue or async HTTP call."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "Serialization",
    "url": "https://docs.python.org/3/library/json.html",
    "urlCorrect": null,
    "text": "What is serialization?\n\nSerialization is the process of converting an in-memory object (like a Python `dict`, class instance, or model output) into a format that can be stored, sent over a network, or written to disk ‚Äî usually something like JSON, bytes, or a binary protocol. The reverse process is called deserialization, which reconstructs the object back into usable program data.\n\nFor example, inside your Python backend you might have:\n\n```\n{\"user_id\": 5, \"score\": 0.92}\n```\n\nBefore sending it to another service, it gets serialized into JSON (the same representation here). When the other service receives it, it deserializes that JSON back into its own data structure.\n\nSerialization matters because computers can't directly transmit complex in-memory objects (like Python classes, tensors, or ORM models) ‚Äî they must be flattened into a standard transferable representation first. In ML systems, serialization overhead can include converting images, tensors, or embeddings into bytes or JSON, which adds a small amount of processing time and payload size. In short: serialization = turning program objects into transferable data; deserialization = rebuilding them on the other side.\n\nBackend engineers often choose between formats in production (e.g. JSON vs Protobuf vs MessagePack); that decision becomes very relevant once you start splitting ML into microservices."
  },
  {
    "date": "Feb 18, 9.45 am",
    "name": "JSON vs Protobuf vs MessagePack",
    "url": "https://developers.google.com/protocol-buffers",
    "urlCorrect": null,
    "text": "Here are the three serialization formats backend engineers most commonly choose in production ‚Äî JSON, Protobuf, and MessagePack ‚Äî and when each makes sense.\n\nüü¢ JSON (JavaScript Object Notation) ‚Äî the default everywhere\n\nJSON is a human-readable text format and the universal standard for web APIs. It's extremely easy to debug, supported natively in browsers and every programming language, and perfect for REST APIs, configuration, and general service communication. The downside is that it's relatively verbose (large payload size) and slower to parse compared to binary formats, especially for large ML inputs/outputs or high-throughput systems. Despite this, most companies still use JSON for external APIs because developer productivity and interoperability matter more than raw efficiency. Rule of thumb: use JSON unless you have a concrete performance reason not to.\n\nüîµ Protobuf (Protocol Buffers) ‚Äî the high-performance structured choice\n\nProtobuf is a compact binary serialization format created by Google that requires you to define a strict schema (`.proto` file) describing your data structures. It produces much smaller payloads than JSON and serializes/deserializes very fast, making it popular for microservice-to-microservice communication, internal APIs, and high-scale systems (especially with `gRPC`). The tradeoff is reduced human readability and more setup: you must maintain schemas and generate code for each language. Protobuf shines when you have many services talking frequently, large payloads, or need strong contracts between teams.\n\nüü£ MessagePack ‚Äî the \"binary JSON\" middle ground\n\nMessagePack is a binary format designed to represent the same data structures as JSON but in a compact binary form. It keeps JSON's flexible schema-less style (no proto files needed) while shrinking payload size and improving speed, so it's often described as \"JSON but faster and smaller.\" It's simpler to adopt than Protobuf and still efficient, which makes it useful for internal APIs, caching layers, or streaming structured data where JSON is too heavy but strict schemas feel overkill. The downside is it's less standardized across big enterprise systems than JSON or Protobuf. Think of MessagePack as the pragmatic performance upgrade when JSON starts hurting but you don't want schema bureaucracy.\n\nüß† The real-world decision shortcut engineers use\n\nüåç Public API ‚Üí JSON (almost always)\n\nüè¢ Internal microservices at scale ‚Üí Protobuf (often with gRPC)\n\n‚öôÔ∏è Need smaller/faster than JSON but want flexibility ‚Üí MessagePack"
  },
  {
    "date": "Feb 18, 10.09 am",
    "name": "Django project vs app",
    "url": "https://docs.djangoproject.com/en/stable/intro/tutorial01/",
    "urlCorrect": null,
    "text": "Now that your environment ‚Äì a \"project\" ‚Äì is set up, you're set to start doing work.\n\nEach application you write in Django consists of a Python package that follows a certain convention. Django comes with a utility that automatically generates the basic directory structure of an app, so you can focus on writing code rather than creating directories.\n\nProjects vs. apps\n\nWhat's the difference between a project and an app? An app is a web application that does something ‚Äì e.g., a blog system, a database of public records or a small poll app. A project is a collection of configuration and apps for a particular website. A project can contain multiple apps. An app can be in multiple projects."
  },
  {
    "date": "Feb 18, 10.11 am",
    "name": "django-admin and manage.py",
    "url": "https://docs.djangoproject.com/en/stable/ref/django-admin/",
    "urlCorrect": null,
    "text": "django-admin and manage.py¬∂\n`django-admin` is Django's command-line utility for administrative tasks. This document outlines all it can do.\n\nIn addition, `manage.py` is automatically created in each Django project. It does the same thing as `django-admin` but also sets the `DJANGO_SETTINGS_MODULE` environment variable so that it points to your project's `settings.py` file.\n\nThe `django-admin` script should be on your system path if you installed Django via `pip`. If it's not in your path, ensure you have your virtual environment activated.\n\nGenerally, when working on a single Django project, it's easier to use `manage.py` than `django-admin`. If you need to switch between multiple Django settings files, use `django-admin` with `DJANGO_SETTINGS_MODULE` or the `--settings` command line option.\n\nThe command-line examples throughout this document use `django-admin` to be consistent, but any example can use `manage.py` or `python -m django` just as well.\n\nUsage¬∂\n\n```\n$ django-admin <command> [options]\n$ manage.py <command> [options]\n$ python -m django <command> [options]\n```"
  },
  {
    "date": "Feb 18, 10.37 am",
    "name": "Install Apache and mod_wsgi",
    "url": "https://docs.djangoproject.com/en/stable/howto/deployment/wsgi/modwsgi/",
    "urlCorrect": null,
    "text": "Install Apache and mod_wsgi¬∂\nIf you just want to experiment with Django, skip ahead to the next section; Django includes a lightweight web server you can use for testing, so you won't need to set up Apache until you're ready to deploy Django in production.\n\nIf you want to use Django on a production site, use Apache with `mod_wsgi`. `mod_wsgi` operates in one of two modes: embedded mode or daemon mode. In embedded mode, `mod_wsgi` is similar to `mod_perl` ‚Äì it embeds Python within Apache and loads Python code into memory when the server starts. Code stays in memory throughout the life of an Apache process, which leads to significant performance gains over other server arrangements. In daemon mode, `mod_wsgi` spawns an independent daemon process that handles requests. The daemon process can run as a different user than the web server, possibly leading to improved security. The daemon process can be restarted without restarting the entire Apache web server, possibly making refreshing your codebase more seamless. Consult the mod_wsgi documentation to determine which mode is right for your setup. Make sure you have Apache installed with the `mod_wsgi` module activated. Django will work with any version of Apache that supports mod_wsgi.\n\nSee How to use Django with mod_wsgi for information on how to configure mod_wsgi once you have it installed.\n\nIf you can't use mod_wsgi for some reason, fear not: Django supports many other deployment options. One is `uWSGI`; it works very well with `nginx`. Additionally, Django follows the WSGI spec (`PEP 3333`), which allows it to run on a variety of server platforms."
  },
  {
    "date": "Feb 18",
    "name": "PostgreSQL Transaction Isolation",
    "url": "https://www.postgresql.org/docs/current/transaction-iso.html",
    "urlCorrect": null,
    "text": "Note: explore this later.\n\n13.2. Transaction Isolation\n13.2.1. Read Committed Isolation Level\n13.2.2. Repeatable Read Isolation Level\n13.2.3. Serializable Isolation Level\n\nThe SQL standard defines four levels of transaction isolation. The most strict is `Serializable`, which is defined by the standard in a paragraph which says that any concurrent execution of a set of Serializable transactions is guaranteed to produce the same effect as running them one at a time in some order. The other three levels are defined in terms of phenomena, resulting from interaction between concurrent transactions, which must not occur at each level. The standard notes that due to the definition of Serializable, none of these phenomena are possible at that level. (This is hardly surprising ‚Äì if the effect of the transactions must be consistent with having been run one at a time, how could you see any phenomena caused by interactions?)"
  },
  {
    "date": "Feb 18",
    "name": "What is Apache?",
    "url": "https://httpd.apache.org/docs/2.4/",
    "urlCorrect": null,
    "text": "Apache usually refers to Apache HTTP Server (often just called \"Apache\"), which is one of the oldest and most widely used web servers in the world. A web server's job is to listen for requests from browsers (like when someone visits your site) and send back the correct web pages, files, or API responses. Apache can serve static files (HTML, images, CSS), forward dynamic requests to application servers (like Django, PHP, or Node apps), handle HTTPS encryption, logging, routing, and access control.\n\nIn a Python/Django setup, Apache is sometimes used together with a connector like `mod_wsgi` so it can run your Django application, although many modern deployments instead use `Nginx` + `Gunicorn`/`Uvicorn` because they're lighter and simpler for async workloads. Apache is extremely configurable and battle-tested, which is why it powered a huge portion of the early web and is still common in enterprise environments.\n\nImportant note: the name \"Apache\" also appears in many other big projects from the Apache Software Foundation (like Apache Spark, Apache Kafka, Apache Airflow), but if someone just says \"Apache\" in a web context, they almost always mean the Apache HTTP Server.\n\nIf you want, I can also explain in one simple diagram-style explanation:\n\n```\nBrowser ‚Üí Apache/Nginx ‚Üí App server ‚Üí Django/FastAPI ‚Üí DB\n```\n\nThat flow is something every backend engineer eventually needs to understand."
  },
  {
    "date": "Feb 18",
    "name": "Apache vs Uvicorn",
    "url": "https://www.uvicorn.org/",
    "urlCorrect": null,
    "text": "Yes ‚Äî **they're both servers that sit in front of your app**, but they are *not the same type* of server in practice. They live at different layers.\n\nHere's the clean way to think about it:\n\n---\n\n### üß± Apache = full general-purpose web server\n\nApache HTTP Server is a **complete front-facing web server**. It can:\n\n* accept internet traffic directly\n* serve static files (HTML, images, CSS)\n* terminate HTTPS\n* handle routing, compression, logging\n* optionally run apps via modules (like `mod_wsgi`)\n\nIt's designed to be the **main entry point from the internet**.\n\n---\n\n### ‚ö° Uvicorn = Python application server (ASGI server)\n\nUvicorn is specifically an **ASGI application server for Python apps**.\n\nIt:\n\n* runs FastAPI / Django ASGI apps\n* understands Python async protocols\n* converts HTTP requests into ASGI calls\n\nBut it does *not* aim to be a full-featured general web server like Apache.\n\nThink of it as:\n\n> \"the engine that executes your Python web app.\"\n\n---\n\n### üß† Real production architecture\n\nMost modern setups look like:\n\n```\nBrowser\n   ‚Üì\nNginx / Apache   ‚Üê front web server (TLS, static files)\n   ‚Üì\nUvicorn / Gunicorn  ‚Üê app server\n   ‚Üì\nDjango / FastAPI\n```\n\nSo:\n\n* Apache/Nginx = traffic manager + front door\n* Uvicorn = Python request runner\n\n---\n\n### üéØ Simple analogy\n\n* **Apache = restaurant building + reception + security**\n* **Uvicorn = the kitchen cooking the food**\n\nBoth are part of serving customers, but they do different jobs.\n\n---\n\n### ‚úÖ The technically correct statement\n\n‚úî Both handle HTTP traffic\n‚úî Both are servers\n‚ùå But Apache is a *web server*, while Uvicorn is an *application server*\n\n---\n\nIf you want the *real industry shortcut* senior engineers use:\n\nüëâ **When do you actually need Nginx/Apache in front of Uvicorn, and when can you safely run Uvicorn alone?**\n\nThat's something beginners almost always misunderstand in deployment."
  },
  {
    "date": "Feb 18",
    "name": "How the web actually works",
    "url": "https://developer.mozilla.org/en-US/docs/Web/HTTP",
    "urlCorrect": null,
    "text": "Note: requires further study.\n\n**Absolute foundation** for understanding web servers, async vs sync, and deployment.\n\nStudy: HTTP request/response lifecycle; DNS ‚Üí TCP ‚Üí TLS ‚Üí HTTP flow; what a browser actually sends; headers, cookies, sessions; REST vs WebSockets.\n\nIf you deeply understand:\n\n```\nBrowser ‚Üí Internet ‚Üí Server ‚Üí Response\n```\n\n‚Ä¶everything else becomes easier. This is the single highest-leverage topic."
  },
  {
    "date": "Feb 18",
    "name": "Operating systems basics (for backend)",
    "url": "https://en.wikipedia.org/wiki/Process_(computing)",
    "urlCorrect": null,
    "text": "Note: requires further study.\n\n**Very important, often skipped.** You don't need a full OS course, just: processes vs threads; blocking vs non-blocking I/O; scheduling; memory vs CPU usage; file descriptors / sockets.\n\nThis explains: why CPU-bound work slows servers; why async exists; why worker processes exist. Without this, async vs sync feels like magic."
  },
  {
    "date": "Feb 18",
    "name": "Networking fundamentals",
    "url": "https://beej.us/guide/bgnet/",
    "urlCorrect": null,
    "text": "Note: requires further study.\n\nLearn: what a socket is; what \"listening on a port\" means; how servers accept connections; latency vs throughput; serialization / payload transfer.\n\nThis explains: why microservices add network overhead; why JSON vs Protobuf matters; why load balancers exist."
  },
  {
    "date": "Feb 18",
    "name": "Backend architecture patterns",
    "url": "https://microservices.io/patterns/index.html",
    "urlCorrect": null,
    "text": "Note: requires further study.\n\n**Industry reality.** Understand: monolith vs microservices; reverse proxy vs app server; background workers & queues; horizontal vs vertical scaling; stateless vs stateful services.\n\nThis explains: Apache vs Uvicorn; Django vs FastAPI roles; why Celery exists; why Cloud Run / containers exist."
  },
  {
    "date": "Feb 18",
    "name": "Concurrency models",
    "url": "https://docs.python.org/3/library/asyncio.html",
    "urlCorrect": null,
    "text": "Note: requires further study.\n\n**This unlocks everything.** Learn the difference between: synchronous execution; threading; multiprocessing; event loops; async/await.\n\nOnce you truly understand:\n\n```\nCPU-bound vs IO-bound\n```\n\n‚Ä¶90% of backend scaling decisions become obvious. This is the core mental model of modern backend engineering."
  },
  {
    "date": "Feb 18, 11.22 am",
    "name": "Access shell inside a Docker container",
    "url": "https://docs.docker.com/engine/reference/commandline/exec/",
    "urlCorrect": null,
    "text": "`docker exec -it <container> bash` opens an **interactive Bash shell inside a running Docker container**. `docker exec` means \"run a command in this existing container\"; `-i` keeps input open and `-t` gives you a real terminal; `<container>` is the container name or ID; and `bash` is the shell you want to start. Once inside, you're effectively \"logged into\" the container and can inspect files, run programs, check logs, or manually execute things like `psql`, `python`, or migrations. It's the Docker equivalent of SSH-ing into a remote machine for debugging or manual work."
  },
  {
    "date": "Feb 18, 11.23 am",
    "name": "Connecting to a database inside a Docker container",
    "url": "https://docs.docker.com/engine/reference/commandline/exec/",
    "urlCorrect": null,
    "text": "The correct way to connect to a database (e.g. Postgres) inside a running Docker container is:\n\n```\ndocker exec -it <container> psql -U <user> -d <db-name>\n```\n\nThis means: run the Postgres CLI (psql) inside the container, open an interactive terminal (-it), log in as the specified database user (-U <user>), and connect to the given database (-d <db-name>). In practice, it's the fastest way to jump straight into a specific database inside your container without first opening a shell and then connecting manually ‚Äî very useful for debugging, running SQL, or inspecting tables."
  },
  {
    "date": "Feb 18, 11.40 am",
    "name": "Django models",
    "url": "https://docs.djangoproject.com/en/stable/intro/tutorial02/",
    "urlCorrect": null,
    "text": "Creating models\nNow we'll define your models ‚Äì essentially, your database layout, with additional metadata.\n\nPhilosophy\n\nA model is the single, definitive source of information about your data. It contains the essential fields and behaviors of the data you're storing. Django follows the DRY Principle. The goal is to define your data model in one place and automatically derive things from it.\n\nThis includes the migrations: unlike in Ruby On Rails, for example, migrations are entirely derived from your models file, and are essentially a history that Django can roll through to update your database schema to match your current models. The `migrate` command takes all migrations that haven't been applied yet (Django tracks which ones are applied in a special table called `django_migrations`) and runs them against your database‚Äîsynchronizing your model changes with the schema. Migrations are powerful: they let you change your models over time as you develop, without deleting your database or tables. They specialize in upgrading your database live, without losing data. Remember the three-step guide to making model changes: (1) Change your models in `models.py`. (2) Run `python manage.py makemigrations` to create migrations for those changes. (3) Run `python manage.py migrate` to apply them to the database. The reason there are separate commands to make and apply migrations is that you commit migrations to version control and ship them with your app‚Äîthey're used by other developers and in production as well. See the django-admin documentation for full information on what the `manage.py` utility can do.\n\nIn our poll app, we'll create two models: Question and Choice. A Question has a question and a publication date. A Choice has two fields: the text of the choice and a vote tally. Each Choice is associated with a Question.\n\nThese concepts are represented by Python classes. Edit the polls/models.py file so it looks like this:\n\n```\nfrom django.db import models\n\n\nclass Question(models.Model):\n    question_text = models.CharField(max_length=200)\n    pub_date = models.DateTimeField(\"date published\")\n\n\nclass Choice(models.Model):\n    question = models.ForeignKey(Question, on_delete=models.CASCADE)\n    choice_text = models.CharField(max_length=200)\n    votes = models.IntegerField(default=0)\n```\n\nHere, each model is represented by a class that subclasses `django.db.models.Model`. Each model has a number of class variables, each of which represents a database field in the model.\n\nEach field is represented by an instance of a Field class ‚Äì e.g., `CharField` for character fields and `DateTimeField` for datetimes. This tells Django what type of data each field holds.\n\nThe name of each Field instance (e.g. `question_text` or `pub_date`) is the field's name, in machine-friendly format. You'll use this value in your Python code, and your database will use it as the column name.\n\nYou can use an optional first positional argument to a Field to designate a human-readable name. That's used in a couple of introspective parts of Django, and it doubles as documentation. If this field isn't provided, Django will use the machine-readable name. In this example, we've only defined a human-readable name for `Question.pub_date`. For all other fields in this model, the field's machine-readable name will suffice as its human-readable name.\n\nSome Field classes have required arguments. `CharField`, for example, requires that you give it a `max_length`. That's used not only in the database schema, but in validation, as we'll soon see.\n\nA Field can also have various optional arguments; in this case, we've set the default value of `votes` to 0.\n\nFinally, note a relationship is defined, using `ForeignKey`. That tells Django each Choice is related to a single Question. Django supports all the common database relationships: many-to-one, many-to-many, and one-to-one."
  }
]
